---
title: "Covid-19 Mental Health"
output: html_notebook
---

## Load packages
```{r}
library(tidyverse)
library(readxl)
library(tibbletime)
library(lubridate)
```

Observational period between March 5 and September 5, 2020
```{r}
# volume data
cmh_ed <- read_excel('data/ED Volume Cambridge.xlsx')
grh_ed <- read_excel('data/ED volumes GRH.xlsx')
smh_ed <- read_excel('data/ED volumes SMH.xlsx')

# mental health data
cmh_mh <- read_excel('data/COVID-19 data sheet edited Jan 23.xlsx', sheet='cmh') %>%
  replace(is.na(.), 0) %>% 
  pivot_longer(cols = `March 1 - March 7`:`August 30th - September 5th`,
               names_to='week',
               values_to='count')

grh_mh <- read_excel('data/COVID-19 data sheet edited Jan 23.xlsx', sheet='grh') %>%
  replace(is.na(.), 0) %>% 
  pivot_longer(cols = `March 1 - March 7`:`August 30th - September 5th`,
               names_to='week',
               values_to='count')

smh_mh <- read_excel('data/COVID-19 data sheet edited Jan 23.xlsx', sheet='smh') %>%
  replace(is.na(.), 0) %>% 
  pivot_longer(cols = `March 1 - March 7`:`August 30th - September 5th`,
               names_to='week',
               values_to='count')

# Police data
police <- read_excel('data/COVID-19 data sheet edited Jan 23.xlsx', sheet='pol')
```

Get total volume
```{r}
vol <- smh_ed %>% left_join(grh_ed, by=c("Date of ED visit (reg)" = "Day of Triage_DT")) %>% 
  left_join(cmh_ed, by=c("Date of ED visit (reg)" = "Triage Date")) %>% 
  rename(date=`Date of ED visit (reg)`, smh=`# of cases`, grh=`Number of Records`, cmh=Volume) %>% 
  mutate(total=smh+grh+cmh) %>% 
  mutate(year=as.factor(year(date)))
```

ED visits during lockdown  
Line graph
```{r}
p <- vol %>% drop_na() %>% 
  mutate(date = if_else(year==2019, date+years(1), date)) %>%
  ggplot(aes(x=date, y=total, color=year)) +
  geom_line() +
  scale_color_manual(values=c("green", "blue")) +
  ylab('daily ED visits') +
  annotate('rect', xmin=as.POSIXct('2020-03-17'), xmax=as.POSIXct('2020-05-04'),
           ymin=-Inf, ymax=Inf, fill='red', alpha=0.3)
ggsave('graphs/vol.png', p, height = 8.5, width = 11, units = 'in')
p
```

Histogram (for potential ANOVA)
```{r}
vol %>% mutate(date=as.Date(date)) %>% 
  filter(date>='2019-03-17' & date<='2020-05-04') %>% 
  filter(date<='2019-05-04' | date>='2020-03-17') %>% 
  ggplot(aes(x=total, fill=year)) +
  geom_histogram()
```

Poisson ED visits during lockdown  
  
We're looking at the difference in outcome (hospitalizations) based on at least one predictor (year). That's general linear model territory. If you are summarizing over some period (e.g., the average across the shaded area), then the formulation of GLM that we refer to as ANOVA for shorthand would probably be OK. If you are not summarizing, and are using the individual data points, then you'll be violating some of the assumptions of GLM -- our observations are not independent, because the rate on Oct 2 is more related to the rate on Oct 3 than it is to April 3 (for example). In other words, these are time series data, where there is a trend happening, and to ignore that would violate the assumption of (residual) independence.  
  
Second, we might be violating the assumption that our residuals are normally distributed, because we know this type of data (counts) has been drawn from something other than a normal distribution, because only integers are possible and the counts are bounded at zero (normal distribution has limits of +/- infinity). So, we should be thinking about altering our GLM to expect a different distribution, like Poisson. However, it turns out that because the big problem with count data is the boundary at zero, when our counts are all far away from zero, the results of a model where we assume a normal distribution and where we assume a Poisson distribution converge. In the normal distribution, you get decimal points in your estimate, which don't really make sense (can't have half an ER visit), but this can easily be ignored. If you can live with that, then you might do the ANOVA. But, if you can stomach it, Poisson is the more correct version.  
  
In summary, can't use ANOVA because it violates two assumptions:  
1. The observations are not independent  
2. The residuals are not normally distributed  
  
We use Poisson regression because:  
1. It can handle observations that are not independent  
2. Counts are drawn from something other than a normal distribution, i.e. a Poisson distribution  
  
Before starting to interpret results, letâ€™s check whether the model has over-dispersion or under-dispersion. If the Residual Deviance is greater than the degrees of freedom, then over-dispersion exists. This means that the estimates are correct, but the standard errors (standard deviation) are wrong and unaccounted for by the model.  
  
So, to have a more correct standard error we can use a quasi-poisson model:
```{r}
data <- vol %>% mutate(date=as.Date(date)) %>% 
  filter(date>='2019-03-17' & date<='2020-05-04') %>% 
  filter(date<='2019-05-04' | date>='2020-03-17')

# Poisson regression
poisson_out <- glm(total ~ year, family='quasipoisson', data=data)
summary(poisson_out)
```

```{r}
get_data <- function(data, type, subtype=NULL) {
  if (is.null(subtype)) {
    smh <- data$smh_mh %>%
      filter(Type==type) %>% 
      group_by(Year, week) %>% 
      summarize(count=sum(count)) %>% 
      mutate(date=paste(week, Year, sep=' '))
    grh <- data$grh_mh %>%
      filter(Type==type) %>% 
      group_by(Year, week) %>% 
      summarize(count=sum(count)) %>% 
      mutate(date=paste(week, Year, sep=' '))
    cmh <- data$cmh_mh %>%
      filter(Type==type) %>% 
      group_by(Year, week) %>% 
      summarize(count=sum(count)) %>% 
      mutate(date=paste(week, Year, sep=' '))
  } else {
    smh <- data$smh_mh %>%
      filter(Type==type, Subtype==subtype) %>% 
      group_by(Year, week) %>% 
      summarize(count=sum(count)) %>% 
      mutate(date=paste(week, Year, sep=' '))
    grh <- data$grh_mh %>%
      filter(Type==type, Subtype==subtype) %>% 
      group_by(Year, week) %>% 
      summarize(count=sum(count)) %>% 
      mutate(date=paste(week, Year, sep=' '))
    cmh <- data$cmh_mh %>%
      filter(Type==type, Subtype==subtype) %>% 
      group_by(Year, week) %>% 
      summarize(count=sum(count)) %>% 
      mutate(date=paste(week, Year, sep=' '))
  }
  whole <- smh %>% 
    left_join(grh, by='date') %>%
    left_join(cmh, by='date') %>% 
    mutate(total=count+count.x+count.y) %>% 
    select(Year, week, total) %>% 
    mutate(Year=as.factor(Year))
  return(whole)
}
```

Mental health data
```{r}
mh <- list(smh_mh=smh_mh, grh_mh=grh_mh, cmh_mh=cmh_mh)
```

Involuntary - Form 1 
```{r}
data <- get_data(mh, 'Form 1 Total')

# Poisson regression
poisson_out <- glm(total ~ Year, data=data, family='quasipoisson')
summary(poisson_out)
```

Substance related
```{r}
data <- get_data(mh, 'Substance related')

# Poisson regression
poisson_out <- glm(total ~ Year, data=data, family='quasipoisson')
summary(poisson_out)
```

Alcohol Related
```{r}
data <- get_data(mh, 'Substance related', 'Alcohol (separate)')

# Poisson regression
poisson_out <- glm(total ~ Year, data=data, family='quasipoisson')
summary(poisson_out)
```

Mood related
```{r}
data <- get_data(mh, 'Mood related')

# Poisson regression
poisson_out <- glm(total ~ Year, data=data, family='quasipoisson')
summary(poisson_out)
```

Psychosis related
```{r}
data <- get_data(mh, 'Psychosis related')

# Poisson regression
poisson_out <- glm(total ~ Year, data=data, family='quasipoisson')
summary(poisson_out)
```

Situational crisis
```{r}
data <- get_data(mh, 'Situational crisis')

# Poisson regression
poisson_out <- glm(total ~ Year, data=data, family='quasipoisson')
summary(poisson_out)
```

Self harm related
```{r}
data <- get_data(mh, 'Self harm')

# Poisson regression
poisson_out <- glm(total ~ Year, data=data, family='quasipoisson')
summary(poisson_out)
```
